apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otelcol-dso
  namespace: observability
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.51.0
  imagePullPolicy: IfNotPresent
  replicas: 2
  ports:
    - port: 55678
      name: opencensus
    - port: 55679
      name: zpages
    - port: 4318
      name: otlp-http
    - port: 4317
      name: otlp-grpc
    - port: 9411
      name: zipkin
    - port: 8888
      name: metrics
  resources:
    limits:
      cpu: 1
      memory: 6Gi
    requests:
      cpu: 1
      memory: 3Gi
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: K8S_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: K8S_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: K8S_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
  config: |
    receivers:
      otlp:
        protocols:
          http:
            endpoint: "0.0.0.0:4318"
          grpc:
            endpoint: "0.0.0.0:4317"
            max_recv_msg_size_mib: 99999999
      opencensus:
        endpoint: "0.0.0.0:55678"
      zipkin:
        endpoint: "0.0.0.0:9411"
      jaeger:
        protocols:
          grpc:
            endpoint: "0.0.0.0:14250"
      prometheus:
        config:
          scrape_configs:
            - job_name: 'otelcol-metrics-dso'
              scrape_interval: 30s
              static_configs:
                - targets: ['0.0.0.0:8888']
            
      # Dummy receiver that's never used, because a pipeline is required to have one.
      #otlp/spanmetrics:
      #  protocols:
      #    grpc:
      #      endpoint: "localhost:12345"

    processors:
      memory_limiter:
        check_interval: 1s
        limit_percentage: 80
        spike_limit_percentage: 30
      batch:
        timeout: 1s
        send_batch_size: 2048
        send_batch_max_size: 2048
      filter/k8sevents:
        logs:
          include:
            match_type: regexp
            record_attributes:
              - key: k8s.event.uid
                # NOT EMPTY
                value: ^.*
      #spanmetrics:
      #  metrics_exporter: "kafka/metrics"
      #  #latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
      #  #dimensions:
      #  #  - name: http.method
      #  #    default: GET
      #  #  - name: http.status_code
      #  dimensions_cache_size: 2000
      #  aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"

    exporters:
      logging:
        #loglevel: debug
      otlp/spanmetrics:
        endpoint: "localhost:4317"
        tls:
          insecure: true
      otlp/test:
        endpoint: "otelcol-test-collector.observability:4317"
        tls:
          insecure: true
      loki:
        #endpoint: "http://loki-write.observability:3100/loki/api/v1/push"
        # cloki
        endpoint: "http://cloki.observability:3100/loki/api/v1/push"
        format: json
        labels:
          resource:
            k8s.cluster.name: "k8s_cluster"
            k8s.namespace.name: "namespace"
            k8s.deployment.name: "deployment"
            k8s.pod.name: "pod"
            k8s.node.name: "node"
            k8s.pod.labels.app: "app"
            k8s.pod.labels.druid_cr: "druid_cr"
            k8s.pod.labels.component: "component"
            k8s.pod.labels.app.kubernetes.io/component: "app_kubernetes_io_component"
            k8s.pod.labels.app.kubernetes.io/name: "app_kubernetes_io_name"
            k8s.pod.labels.app.kubernetes.io/instance: "app_kubernetes_io_name_instance"
          attributes:
            k8s.namespace.name: "k8s_namespace_name"
            k8s.container.name: "k8s_container_name"
            k8s.pod.name: "k8s_pod_name"
          record:
            traceID: "traceid"
            spanID: "spanid"
      kafka/traces:
        protocol_version: 3.0.0
        topic: "otel-traces-default"
        brokers:
          - "dso-kafka-bootstrap.kafka:9092"
        encoding: "otlp_proto"
        producer:
          max_message_bytes: 16000000
          compression: snappy
        timeout: 10s
      kafka/metrics:
        protocol_version: 3.0.0
        topic: "otel-metrics-default"
        brokers:
          - "dso-kafka-bootstrap.kafka:9092"
        encoding: "otlp_proto"
        producer:
          max_message_bytes: 16000000
          compression: snappy
        timeout: 10s
      kafka/logs:
        protocol_version: 3.0.0
        topic: "otel-logs-default"
        brokers:
          - "dso-kafka-bootstrap.kafka:9092"
        encoding: "otlp_proto"
        producer:
          max_message_bytes: 16000000
          compression: snappy
        timeout: 10s
      kafka/k8sevents:
        protocol_version: 3.0.0
        topic: otel-logs-k8sevents
        brokers:
          - "dso-kafka-bootstrap.kafka:9092"
        encoding: otlp_json
        producer:
          max_message_bytes: 16000000
          compression: snappy
        timeout: 10s

      #prometheusremotewrite:
      #  # thanos
      #  endpoint: "http://thanos-receive.observability:19291/api/v1/receive"
      #  resource_to_telemetry_conversion:
      #    enabled: true
      #prometheusremotewrite/promscale:
      #  endpoint: "http://tobs-promscale-connector:9201/write"
      #  tls:
      #    insecure: true

      #otlp/signoz:
      #  endpoint: "signoz-otel-collector.observability:4317"
      #  tls:
      #    insecure: true
      #otlp/signozmetrics:
      #  endpoint: "signoz-otel-collector-metrics.observability:4317"
      #  tls:
      #    insecure: true

      #jaeger:
      #  endpoint: jaeger-collector.observability:14250
      #  tls:
      #    insecure: true
      otlp/promscale:
          endpoint: "tobs-promscale-connector:9202"
          tls:
            insecure: true

    extensions:
      health_check:
      pprof:
      zpages:
        endpoint: 0.0.0.0:55679
      memory_ballast:
        size_in_percentage: 20
        
    service:
      telemetry:
        logs:
          level: "info"
      extensions: [health_check, pprof, zpages, memory_ballast]
      pipelines:
        #traces/jaeger:
        #  receivers: [otlp]
        #  processors: [memory_limiter, batch, spanmetrics]
        #  exporters: [logging, jaeger]
        #traces/signoz:
        #  receivers: [otlp]
        #  processors: [memory_limiter, batch]
        #  exporters: [logging, otlp/signoz]
        #traces/promscale:
        #  receivers: [otlp]
        #  processors: [memory_limiter, batch, spanmetrics]
        #  exporters: [logging, otlp/promscale]
        traces/kafka:
          receivers: [otlp, zipkin]
          processors: [memory_limiter, batch]
          exporters: [logging, kafka/traces]
        #metrics:
        #  receivers: [otlp, prometheus]
        #  processors: [memory_limiter, batch]
        #  exporters: [logging, prometheusremotewrite]
        #metrics/promscale:
        #  receivers: [otlp, prometheus]
        #  processors: [memory_limiter, batch]
        #  exporters: [logging, prometheusremotewrite/promscale]
        metrics/kafka:
          receivers: [otlp, prometheus]
          processors: [memory_limiter, batch]
          exporters: [logging, kafka/metrics]
        #metrics/signozmetrics:
        #  receivers: [otlp, prometheus]
        #  processors: [memory_limiter, batch]
        #  exporters: [otlp/signozmetrics]
        #logs:
        #  receivers: [otlp]
        #  processors: [memory_limiter, batch]
        #  exporters: [logging, loki]
        logs/kafka:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [logging, kafka/logs]
        logs/k8sevents:
          receivers: [otlp]
          processors: [memory_limiter, batch, filter/k8sevents]
          exporters: [logging, kafka/k8sevents]


